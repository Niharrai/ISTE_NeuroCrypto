{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0106 18:52:13.704952 21936 deprecation.py:323] From <ipython-input-1-c9d51d2b37f6>:47: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0106 18:52:13.728312 21936 deprecation.py:506] From C:\\Users\\shrey\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0106 18:52:14.347517 21936 deprecation.py:323] From <ipython-input-1-c9d51d2b37f6>:56: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "C:\\Users\\shrey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   Alice_bob_loss:  7.9897003     Eve_loss: 8.0262785\n",
      "100   Alice_bob_loss:  5.441805     Eve_loss: 3.2429485\n",
      "200   Alice_bob_loss:  0.70159644     Eve_loss: 3.9050083\n",
      "300   Alice_bob_loss:  0.27835345     Eve_loss: 5.203371\n",
      "400   Alice_bob_loss:  0.1624307     Eve_loss: 5.7575045\n",
      "500   Alice_bob_loss:  0.10843047     Eve_loss: 6.080491\n",
      "600   Alice_bob_loss:  0.06253946     Eve_loss: 6.6213164\n",
      "700   Alice_bob_loss:  0.045173075     Eve_loss: 6.791985\n",
      "800   Alice_bob_loss:  0.032793947     Eve_loss: 6.9683104\n",
      "900   Alice_bob_loss:  0.02484926     Eve_loss: 7.090041\n",
      "1000   Alice_bob_loss:  0.01951921     Eve_loss: 7.180002\n",
      "1100   Alice_bob_loss:  0.016116396     Eve_loss: 7.2320285\n",
      "1200   Alice_bob_loss:  0.012232971     Eve_loss: 7.331219\n",
      "1300   Alice_bob_loss:  0.009621222     Eve_loss: 7.4032917\n",
      "1400   Alice_bob_loss:  0.007843776     Eve_loss: 7.4546127\n",
      "1500   Alice_bob_loss:  0.006453174     Eve_loss: 7.4964256\n",
      "1600   Alice_bob_loss:  0.005459455     Eve_loss: 7.5263596\n",
      "1700   Alice_bob_loss:  0.0044161053     Eve_loss: 7.5692005\n",
      "1800   Alice_bob_loss:  0.007974284     Eve_loss: 7.3326607\n",
      "1900   Alice_bob_loss:  0.0058304765     Eve_loss: 7.4487934\n",
      "2000   Alice_bob_loss:  0.0051281424     Eve_loss: 7.489621\n",
      "2100   Alice_bob_loss:  0.004153433     Eve_loss: 7.5474734\n",
      "2200   Alice_bob_loss:  0.003930027     Eve_loss: 7.5511465\n",
      "2300   Alice_bob_loss:  0.0036086834     Eve_loss: 7.5634694\n",
      "2400   Alice_bob_loss:  0.0033680382     Eve_loss: 7.575075\n",
      "2500   Alice_bob_loss:  0.003214614     Eve_loss: 7.5795836\n",
      "2600   Alice_bob_loss:  0.0028914048     Eve_loss: 7.600376\n",
      "2700   Alice_bob_loss:  0.002865006     Eve_loss: 7.594162\n",
      "2800   Alice_bob_loss:  0.002715515     Eve_loss: 7.603364\n",
      "2900   Alice_bob_loss:  0.010677404     Eve_loss: 7.176424\n",
      "3000   Alice_bob_loss:  0.007453557     Eve_loss: 7.3162436\n",
      "3100   Alice_bob_loss:  0.0057643894     Eve_loss: 7.3981524\n",
      "3200   Alice_bob_loss:  0.0049001244     Eve_loss: 7.447233\n",
      "3300   Alice_bob_loss:  0.0041942596     Eve_loss: 7.490387\n",
      "3400   Alice_bob_loss:  0.0035191493     Eve_loss: 7.5342207\n",
      "3500   Alice_bob_loss:  0.002873334     Eve_loss: 7.583021\n",
      "3600   Alice_bob_loss:  0.002641309     Eve_loss: 7.603268\n",
      "3700   Alice_bob_loss:  0.002493064     Eve_loss: 7.61834\n",
      "3800   Alice_bob_loss:  0.002426291     Eve_loss: 7.621603\n",
      "3900   Alice_bob_loss:  0.0021949923     Eve_loss: 7.6417317\n",
      "4000   Alice_bob_loss:  0.0021299135     Eve_loss: 7.643594\n",
      "4100   Alice_bob_loss:  0.010802279     Eve_loss: 7.168167\n",
      "4200   Alice_bob_loss:  0.0070828064     Eve_loss: 7.3300133\n",
      "4300   Alice_bob_loss:  0.005827071     Eve_loss: 7.394231\n",
      "4400   Alice_bob_loss:  0.004689708     Eve_loss: 7.4575143\n",
      "4500   Alice_bob_loss:  0.0038089398     Eve_loss: 7.5123153\n",
      "4600   Alice_bob_loss:  0.002945112     Eve_loss: 7.5737157\n",
      "4700   Alice_bob_loss:  0.0024477143     Eve_loss: 7.612735\n",
      "4800   Alice_bob_loss:  0.0021915482     Eve_loss: 7.6365466\n",
      "4900   Alice_bob_loss:  0.002131856     Eve_loss: 7.643132\n",
      "5000   Alice_bob_loss:  0.0021473006     Eve_loss: 7.6411204\n",
      "5100   Alice_bob_loss:  0.0020919533     Eve_loss: 7.64534\n",
      "5200   Alice_bob_loss:  0.011139557     Eve_loss: 7.1556654\n",
      "5300   Alice_bob_loss:  0.007586088     Eve_loss: 7.3051424\n",
      "5400   Alice_bob_loss:  0.005864327     Eve_loss: 7.390317\n",
      "5500   Alice_bob_loss:  0.004814762     Eve_loss: 7.4488306\n",
      "5600   Alice_bob_loss:  0.0039804224     Eve_loss: 7.4993606\n",
      "5700   Alice_bob_loss:  0.0032873852     Eve_loss: 7.5474606\n",
      "5800   Alice_bob_loss:  0.002725701     Eve_loss: 7.5887766\n",
      "5900   Alice_bob_loss:  0.0024010662     Eve_loss: 7.616994\n",
      "6000   Alice_bob_loss:  0.002287272     Eve_loss: 7.6280537\n",
      "6100   Alice_bob_loss:  0.002268917     Eve_loss: 7.630127\n",
      "6200   Alice_bob_loss:  0.0020134253     Eve_loss: 7.6512685\n",
      "6300   Alice_bob_loss:  0.0019702984     Eve_loss: 7.654481\n",
      "6400   Alice_bob_loss:  0.012991033     Eve_loss: 7.096926\n",
      "6500   Alice_bob_loss:  0.009864274     Eve_loss: 7.2074156\n",
      "6600   Alice_bob_loss:  0.00734124     Eve_loss: 7.3171725\n",
      "6700   Alice_bob_loss:  0.0057175187     Eve_loss: 7.3985715\n",
      "6800   Alice_bob_loss:  0.0045596156     Eve_loss: 7.464368\n",
      "6900   Alice_bob_loss:  0.0035279612     Eve_loss: 7.5303216\n",
      "7000   Alice_bob_loss:  0.0027431168     Eve_loss: 7.587058\n",
      "7100   Alice_bob_loss:  0.0021818257     Eve_loss: 7.6338625\n",
      "7200   Alice_bob_loss:  0.0020333738     Eve_loss: 7.647912\n",
      "7300   Alice_bob_loss:  0.0020426442     Eve_loss: 7.6479044\n",
      "7400   Alice_bob_loss:  0.0019806447     Eve_loss: 7.6520247\n",
      "7500   Alice_bob_loss:  0.009759456     Eve_loss: 7.211263\n",
      "7600   Alice_bob_loss:  0.0077818544     Eve_loss: 7.2966623\n",
      "7700   Alice_bob_loss:  0.006171799     Eve_loss: 7.373638\n",
      "7800   Alice_bob_loss:  0.004895403     Eve_loss: 7.444377\n",
      "7900   Alice_bob_loss:  0.0039765867     Eve_loss: 7.499653\n",
      "8000   Alice_bob_loss:  0.0031906976     Eve_loss: 7.553325\n",
      "8100   Alice_bob_loss:  0.0026026159     Eve_loss: 7.597335\n",
      "8200   Alice_bob_loss:  0.0021345273     Eve_loss: 7.6392336\n",
      "8300   Alice_bob_loss:  0.0021482739     Eve_loss: 7.638837\n",
      "8400   Alice_bob_loss:  0.0020383059     Eve_loss: 7.647394\n",
      "8500   Alice_bob_loss:  0.01140748     Eve_loss: 7.147245\n",
      "8600   Alice_bob_loss:  0.009519578     Eve_loss: 7.220517\n",
      "8700   Alice_bob_loss:  0.007309533     Eve_loss: 7.317936\n",
      "8800   Alice_bob_loss:  0.005918012     Eve_loss: 7.3864937\n",
      "8900   Alice_bob_loss:  0.004733593     Eve_loss: 7.453063\n",
      "9000   Alice_bob_loss:  0.0038511753     Eve_loss: 7.5064454\n",
      "9100   Alice_bob_loss:  0.0031528051     Eve_loss: 7.555249\n",
      "9200   Alice_bob_loss:  0.002573582     Eve_loss: 7.601348\n",
      "9300   Alice_bob_loss:  0.0022453773     Eve_loss: 7.629524\n",
      "9400   Alice_bob_loss:  0.0022597974     Eve_loss: 7.627879\n",
      "9500   Alice_bob_loss:  0.0023506582     Eve_loss: 7.6217437\n",
      "9600   Alice_bob_loss:  0.011682157     Eve_loss: 7.144392\n",
      "9700   Alice_bob_loss:  0.00882167     Eve_loss: 7.2504706\n",
      "9800   Alice_bob_loss:  0.0072764647     Eve_loss: 7.319373\n",
      "9900   Alice_bob_loss:  0.0059594586     Eve_loss: 7.3852024\n",
      "10000   Alice_bob_loss:  0.004877411     Eve_loss: 7.4444203\n",
      "10100   Alice_bob_loss:  0.003621717     Eve_loss: 7.5226126\n",
      "10200   Alice_bob_loss:  0.0028090964     Eve_loss: 7.5810213\n",
      "10300   Alice_bob_loss:  0.0023578086     Eve_loss: 7.617691\n",
      "10400   Alice_bob_loss:  0.0022776031     Eve_loss: 7.625714\n",
      "10500   Alice_bob_loss:  0.013081829     Eve_loss: 7.093622\n",
      "10600   Alice_bob_loss:  0.009712942     Eve_loss: 7.2118926\n",
      "10700   Alice_bob_loss:  0.007801111     Eve_loss: 7.2942696\n",
      "10800   Alice_bob_loss:  0.006361472     Eve_loss: 7.3644114\n",
      "10900   Alice_bob_loss:  0.005309874     Eve_loss: 7.4198503\n",
      "11000   Alice_bob_loss:  0.004359627     Eve_loss: 7.474884\n",
      "11100   Alice_bob_loss:  0.003388896     Eve_loss: 7.537909\n",
      "11200   Alice_bob_loss:  0.002617642     Eve_loss: 7.5954456\n",
      "11300   Alice_bob_loss:  0.0020359347     Eve_loss: 7.645443\n",
      "11400   Alice_bob_loss:  0.0020669152     Eve_loss: 7.6436796\n",
      "11500   Alice_bob_loss:  0.014309773     Eve_loss: 7.043677\n",
      "11600   Alice_bob_loss:  0.011393177     Eve_loss: 7.146696\n",
      "11700   Alice_bob_loss:  0.008664689     Eve_loss: 7.255992\n",
      "11800   Alice_bob_loss:  0.0073279105     Eve_loss: 7.317091\n",
      "11900   Alice_bob_loss:  0.0060577495     Eve_loss: 7.3795643\n",
      "12000   Alice_bob_loss:  0.0050267917     Eve_loss: 7.4346666\n",
      "12100   Alice_bob_loss:  0.0039063436     Eve_loss: 7.5036993\n",
      "12200   Alice_bob_loss:  0.0030034268     Eve_loss: 7.566615\n",
      "12300   Alice_bob_loss:  0.002366431     Eve_loss: 7.615932\n",
      "12400   Alice_bob_loss:  0.002155856     Eve_loss: 7.635369\n",
      "12500   Alice_bob_loss:  0.00214955     Eve_loss: 7.635745\n",
      "12600   Alice_bob_loss:  0.011215132     Eve_loss: 7.151649\n",
      "12700   Alice_bob_loss:  0.008310143     Eve_loss: 7.2709045\n",
      "12800   Alice_bob_loss:  0.006462979     Eve_loss: 7.357939\n",
      "12900   Alice_bob_loss:  0.005247778     Eve_loss: 7.4227257\n",
      "13000   Alice_bob_loss:  0.00436414     Eve_loss: 7.473505\n",
      "13100   Alice_bob_loss:  0.00366657     Eve_loss: 7.5184565\n",
      "13200   Alice_bob_loss:  0.0030408408     Eve_loss: 7.562705\n",
      "13300   Alice_bob_loss:  0.002554507     Eve_loss: 7.600066\n",
      "13400   Alice_bob_loss:  0.002209748     Eve_loss: 7.629653\n",
      "13500   Alice_bob_loss:  0.0021368093     Eve_loss: 7.6363397\n",
      "13600   Alice_bob_loss:  0.0022330976     Eve_loss: 7.6293464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13700   Alice_bob_loss:  0.00953649     Eve_loss: 7.2189255\n",
      "13800   Alice_bob_loss:  0.0072840713     Eve_loss: 7.3177443\n",
      "13900   Alice_bob_loss:  0.005938668     Eve_loss: 7.3855104\n",
      "14000   Alice_bob_loss:  0.004972232     Eve_loss: 7.437976\n",
      "14100   Alice_bob_loss:  0.004357137     Eve_loss: 7.47462\n",
      "14200   Alice_bob_loss:  0.0038407051     Eve_loss: 7.505695\n",
      "14300   Alice_bob_loss:  0.003253446     Eve_loss: 7.547762\n",
      "14400   Alice_bob_loss:  0.002417767     Eve_loss: 7.6109977\n",
      "14500   Alice_bob_loss:  0.009217844     Eve_loss: 7.232827\n",
      "14600   Alice_bob_loss:  0.007261046     Eve_loss: 7.3194747\n",
      "14700   Alice_bob_loss:  0.006014917     Eve_loss: 7.3815546\n",
      "14800   Alice_bob_loss:  0.004989764     Eve_loss: 7.437191\n",
      "14900   Alice_bob_loss:  0.0041259695     Eve_loss: 7.489406\n",
      "15000   Alice_bob_loss:  0.0032786985     Eve_loss: 7.5473795\n",
      "15100   Alice_bob_loss:  0.010252565     Eve_loss: 7.191091\n",
      "15200   Alice_bob_loss:  0.0060922597     Eve_loss: 7.3770866\n",
      "15300   Alice_bob_loss:  0.0044862875     Eve_loss: 7.466324\n",
      "15400   Alice_bob_loss:  0.0034075328     Eve_loss: 7.536237\n",
      "15500   Alice_bob_loss:  0.0026364238     Eve_loss: 7.5937586\n",
      "15600   Alice_bob_loss:  0.002807692     Eve_loss: 7.5791903\n",
      "15700   Alice_bob_loss:  0.0021208632     Eve_loss: 7.6361165\n",
      "15800   Alice_bob_loss:  0.0019219967     Eve_loss: 7.6550393\n",
      "15900   Alice_bob_loss:  0.012869628     Eve_loss: 7.0925617\n",
      "16000   Alice_bob_loss:  0.010137472     Eve_loss: 7.195098\n",
      "16100   Alice_bob_loss:  0.008428275     Eve_loss: 7.2666454\n",
      "16200   Alice_bob_loss:  0.007116026     Eve_loss: 7.3262506\n",
      "16300   Alice_bob_loss:  0.005792621     Eve_loss: 7.3936224\n",
      "16400   Alice_bob_loss:  0.004653685     Eve_loss: 7.4571276\n",
      "16500   Alice_bob_loss:  0.003365754     Eve_loss: 7.538553\n",
      "16600   Alice_bob_loss:  0.002960398     Eve_loss: 7.5682507\n",
      "16700   Alice_bob_loss:  0.0022876922     Eve_loss: 7.6215715\n",
      "16800   Alice_bob_loss:  0.007915521     Eve_loss: 7.289254\n",
      "16900   Alice_bob_loss:  0.006112283     Eve_loss: 7.3750906\n",
      "17000   Alice_bob_loss:  0.004963017     Eve_loss: 7.4373474\n",
      "17100   Alice_bob_loss:  0.00435777     Eve_loss: 7.4738865\n",
      "17200   Alice_bob_loss:  0.0035748086     Eve_loss: 7.5240746\n",
      "17300   Alice_bob_loss:  0.0061224005     Eve_loss: 7.4602504\n",
      "17400   Alice_bob_loss:  0.0029322873     Eve_loss: 7.5690126\n",
      "17500   Alice_bob_loss:  0.0026338422     Eve_loss: 7.6241827\n",
      "17600   Alice_bob_loss:  0.008239442     Eve_loss: 7.2744937\n",
      "17700   Alice_bob_loss:  0.0064105066     Eve_loss: 7.3601155\n",
      "17800   Alice_bob_loss:  0.0055559953     Eve_loss: 7.4053097\n",
      "17900   Alice_bob_loss:  0.004792632     Eve_loss: 7.4477944\n",
      "18000   Alice_bob_loss:  0.0040342812     Eve_loss: 7.494615\n",
      "18100   Alice_bob_loss:  0.0033851746     Eve_loss: 7.537424\n",
      "18200   Alice_bob_loss:  0.004315174     Eve_loss: 7.4760675\n",
      "18300   Alice_bob_loss:  0.0026719312     Eve_loss: 7.58941\n",
      "18400   Alice_bob_loss:  0.004015586     Eve_loss: 7.494378\n",
      "18500   Alice_bob_loss:  0.002637178     Eve_loss: 7.5932894\n",
      "18600   Alice_bob_loss:  0.0034468286     Eve_loss: 7.5317154\n",
      "18700   Alice_bob_loss:  0.0043506254     Eve_loss: 7.4740467\n",
      "18800   Alice_bob_loss:  0.0042151427     Eve_loss: 7.49417\n",
      "18900   Alice_bob_loss:  0.003670077     Eve_loss: 7.516184\n",
      "19000   Alice_bob_loss:  0.0043673436     Eve_loss: 7.4824166\n",
      "19100   Alice_bob_loss:  0.004920711     Eve_loss: 7.450689\n",
      "19200   Alice_bob_loss:  0.0044167414     Eve_loss: 7.481674\n",
      "19300   Alice_bob_loss:  0.0044017723     Eve_loss: 7.470623\n",
      "19400   Alice_bob_loss:  0.006814062     Eve_loss: 7.3407025\n",
      "19500   Alice_bob_loss:  0.004962598     Eve_loss: 7.437914\n",
      "19600   Alice_bob_loss:  0.003916496     Eve_loss: 7.500697\n",
      "19700   Alice_bob_loss:  0.0044845343     Eve_loss: 7.4653234\n",
      "19800   Alice_bob_loss:  0.0038029058     Eve_loss: 7.507006\n",
      "19900   Alice_bob_loss:  0.0027324841     Eve_loss: 7.583467\n",
      "20000   Alice_bob_loss:  0.0044086515     Eve_loss: 7.47037\n",
      "20100   Alice_bob_loss:  0.0049109743     Eve_loss: 7.455948\n",
      "20200   Alice_bob_loss:  0.0040407386     Eve_loss: 7.496748\n",
      "20300   Alice_bob_loss:  0.00429016     Eve_loss: 7.4778275\n",
      "20400   Alice_bob_loss:  0.0046897586     Eve_loss: 7.4611034\n",
      "20500   Alice_bob_loss:  0.004565444     Eve_loss: 7.4662027\n",
      "20600   Alice_bob_loss:  0.0048278817     Eve_loss: 7.447598\n",
      "20700   Alice_bob_loss:  0.0051564914     Eve_loss: 7.439171\n",
      "20800   Alice_bob_loss:  0.004906625     Eve_loss: 7.443568\n",
      "20900   Alice_bob_loss:  0.0046571908     Eve_loss: 7.4507656\n",
      "21000   Alice_bob_loss:  0.0048503377     Eve_loss: 7.4460244\n",
      "21100   Alice_bob_loss:  0.0048152325     Eve_loss: 7.4583097\n",
      "21200   Alice_bob_loss:  0.005026259     Eve_loss: 7.446579\n",
      "21300   Alice_bob_loss:  0.004642377     Eve_loss: 7.4575777\n",
      "21400   Alice_bob_loss:  0.005086191     Eve_loss: 7.4381123\n",
      "21500   Alice_bob_loss:  0.0046007936     Eve_loss: 7.457267\n",
      "21600   Alice_bob_loss:  0.0047087823     Eve_loss: 7.4810038\n",
      "21700   Alice_bob_loss:  0.004585426     Eve_loss: 7.4865093\n",
      "21800   Alice_bob_loss:  0.004457968     Eve_loss: 7.461673\n",
      "21900   Alice_bob_loss:  0.004357325     Eve_loss: 7.486226\n",
      "22000   Alice_bob_loss:  0.0041053467     Eve_loss: 7.4842043\n",
      "22100   Alice_bob_loss:  0.00391923     Eve_loss: 7.499571\n",
      "22200   Alice_bob_loss:  0.004384     Eve_loss: 7.4693756\n",
      "22300   Alice_bob_loss:  0.0043287254     Eve_loss: 7.477267\n",
      "22400   Alice_bob_loss:  0.005041826     Eve_loss: 7.463422\n",
      "22500   Alice_bob_loss:  0.004082178     Eve_loss: 7.4882083\n",
      "22600   Alice_bob_loss:  0.0057623866     Eve_loss: 7.4369125\n",
      "22700   Alice_bob_loss:  0.004558705     Eve_loss: 7.4765663\n",
      "22800   Alice_bob_loss:  0.004608557     Eve_loss: 7.456892\n",
      "22900   Alice_bob_loss:  0.0052957837     Eve_loss: 7.4348345\n",
      "23000   Alice_bob_loss:  0.0051023583     Eve_loss: 7.448929\n",
      "23100   Alice_bob_loss:  0.005032615     Eve_loss: 7.447262\n",
      "23200   Alice_bob_loss:  0.0044532674     Eve_loss: 7.4678555\n",
      "23300   Alice_bob_loss:  0.0043997103     Eve_loss: 7.486747\n",
      "23400   Alice_bob_loss:  0.0043969625     Eve_loss: 7.4707522\n",
      "23500   Alice_bob_loss:  0.004642962     Eve_loss: 7.455607\n",
      "23600   Alice_bob_loss:  0.004692163     Eve_loss: 7.475718\n",
      "23700   Alice_bob_loss:  0.00435864     Eve_loss: 7.4718018\n",
      "23800   Alice_bob_loss:  0.0043729013     Eve_loss: 7.470121\n",
      "23900   Alice_bob_loss:  0.0044836877     Eve_loss: 7.4667063\n",
      "24000   Alice_bob_loss:  0.004807943     Eve_loss: 7.473505\n",
      "24100   Alice_bob_loss:  0.0041022724     Eve_loss: 7.4872456\n",
      "24200   Alice_bob_loss:  0.00445401     Eve_loss: 7.4686337\n",
      "24300   Alice_bob_loss:  0.005922112     Eve_loss: 7.384133\n",
      "24400   Alice_bob_loss:  0.004316639     Eve_loss: 7.4748006\n",
      "24500   Alice_bob_loss:  0.0061958274     Eve_loss: 7.4355597\n",
      "24600   Alice_bob_loss:  0.004375207     Eve_loss: 7.4714117\n",
      "24700   Alice_bob_loss:  0.005977765     Eve_loss: 7.4466076\n",
      "24800   Alice_bob_loss:  0.004604247     Eve_loss: 7.47252\n",
      "24900   Alice_bob_loss:  0.005236411     Eve_loss: 7.4751496\n",
      "25000   Alice_bob_loss:  0.004662088     Eve_loss: 7.4746685\n",
      "25100   Alice_bob_loss:  0.0047566565     Eve_loss: 7.4529715\n",
      "25200   Alice_bob_loss:  0.0048849243     Eve_loss: 7.445829\n",
      "25300   Alice_bob_loss:  0.005344335     Eve_loss: 7.4416957\n",
      "25400   Alice_bob_loss:  0.0050710617     Eve_loss: 7.451085\n",
      "25500   Alice_bob_loss:  0.0052101347     Eve_loss: 7.4236674\n",
      "25600   Alice_bob_loss:  0.0047005424     Eve_loss: 7.4546723\n",
      "25700   Alice_bob_loss:  0.0057523577     Eve_loss: 7.43989\n",
      "25800   Alice_bob_loss:  0.0047236513     Eve_loss: 7.4492893\n",
      "25900   Alice_bob_loss:  0.0069252932     Eve_loss: 7.381834\n",
      "26000   Alice_bob_loss:  0.004277795     Eve_loss: 7.477165\n",
      "26100   Alice_bob_loss:  0.005526576     Eve_loss: 7.425211\n",
      "26200   Alice_bob_loss:  0.00494274     Eve_loss: 7.4381704\n",
      "26300   Alice_bob_loss:  0.006060905     Eve_loss: 7.409871\n",
      "26400   Alice_bob_loss:  0.00526336     Eve_loss: 7.448062\n",
      "26500   Alice_bob_loss:  0.0050554546     Eve_loss: 7.455533\n",
      "26600   Alice_bob_loss:  0.0052154604     Eve_loss: 7.419533\n",
      "26700   Alice_bob_loss:  0.0060459236     Eve_loss: 7.424058\n",
      "26800   Alice_bob_loss:  0.0050013904     Eve_loss: 7.454933\n",
      "26900   Alice_bob_loss:  0.0054338905     Eve_loss: 7.413533\n",
      "27000   Alice_bob_loss:  0.0051742317     Eve_loss: 7.4410596\n",
      "27100   Alice_bob_loss:  0.0048852316     Eve_loss: 7.4559293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27200   Alice_bob_loss:  0.0044554113     Eve_loss: 7.475475\n",
      "27300   Alice_bob_loss:  0.0051118066     Eve_loss: 7.454295\n",
      "27400   Alice_bob_loss:  0.004377752     Eve_loss: 7.47\n",
      "27500   Alice_bob_loss:  0.004965993     Eve_loss: 7.4582872\n",
      "27600   Alice_bob_loss:  0.006013309     Eve_loss: 7.381578\n",
      "27700   Alice_bob_loss:  0.0046694754     Eve_loss: 7.453931\n",
      "27800   Alice_bob_loss:  0.004960051     Eve_loss: 7.4387875\n",
      "27900   Alice_bob_loss:  0.0050420174     Eve_loss: 7.461675\n",
      "28000   Alice_bob_loss:  0.0048376373     Eve_loss: 7.461602\n",
      "28100   Alice_bob_loss:  0.004748526     Eve_loss: 7.4523478\n",
      "28200   Alice_bob_loss:  0.0054259016     Eve_loss: 7.445877\n",
      "28300   Alice_bob_loss:  0.004787991     Eve_loss: 7.443311\n",
      "28400   Alice_bob_loss:  0.0055480925     Eve_loss: 7.458938\n",
      "28500   Alice_bob_loss:  0.0051146075     Eve_loss: 7.440533\n",
      "28600   Alice_bob_loss:  0.0050793886     Eve_loss: 7.43086\n",
      "28700   Alice_bob_loss:  0.005681618     Eve_loss: 7.4027367\n",
      "28800   Alice_bob_loss:  0.0049824854     Eve_loss: 7.434814\n",
      "28900   Alice_bob_loss:  0.004879886     Eve_loss: 7.440614\n",
      "29000   Alice_bob_loss:  0.0052891616     Eve_loss: 7.440386\n",
      "29100   Alice_bob_loss:  0.004787193     Eve_loss: 7.4478817\n",
      "29200   Alice_bob_loss:  0.00690773     Eve_loss: 7.4421988\n",
      "29300   Alice_bob_loss:  0.005979949     Eve_loss: 7.444837\n",
      "29400   Alice_bob_loss:  0.0046720696     Eve_loss: 7.4542146\n",
      "29500   Alice_bob_loss:  0.0051796664     Eve_loss: 7.4372745\n",
      "29600   Alice_bob_loss:  0.005685177     Eve_loss: 7.3962483\n",
      "29700   Alice_bob_loss:  0.004951375     Eve_loss: 7.4370794\n",
      "29800   Alice_bob_loss:  0.0051260334     Eve_loss: 7.454683\n",
      "29900   Alice_bob_loss:  0.0044486825     Eve_loss: 7.4642572\n",
      "30000   Alice_bob_loss:  0.005684522     Eve_loss: 7.4600906\n",
      "30100   Alice_bob_loss:  0.0055593196     Eve_loss: 7.444083\n",
      "30200   Alice_bob_loss:  0.0051284293     Eve_loss: 7.4254394\n",
      "30300   Alice_bob_loss:  0.004923253     Eve_loss: 7.440381\n",
      "30400   Alice_bob_loss:  0.0047020316     Eve_loss: 7.4692802\n",
      "30500   Alice_bob_loss:  0.004924793     Eve_loss: 7.438655\n",
      "30600   Alice_bob_loss:  0.0051998403     Eve_loss: 7.4588003\n",
      "30700   Alice_bob_loss:  0.004626496     Eve_loss: 7.454758\n",
      "30800   Alice_bob_loss:  0.0046179043     Eve_loss: 7.456445\n",
      "30900   Alice_bob_loss:  0.0050462056     Eve_loss: 7.454439\n",
      "31000   Alice_bob_loss:  0.00456898     Eve_loss: 7.4584823\n",
      "31100   Alice_bob_loss:  0.0045613777     Eve_loss: 7.471179\n",
      "31200   Alice_bob_loss:  0.00453781     Eve_loss: 7.4605536\n",
      "31300   Alice_bob_loss:  0.004651833     Eve_loss: 7.480608\n",
      "31400   Alice_bob_loss:  0.004010837     Eve_loss: 7.5006714\n",
      "31500   Alice_bob_loss:  0.003906118     Eve_loss: 7.4996414\n",
      "31600   Alice_bob_loss:  0.004873482     Eve_loss: 7.4810843\n",
      "31700   Alice_bob_loss:  0.0050474023     Eve_loss: 7.445176\n",
      "31800   Alice_bob_loss:  0.005465001     Eve_loss: 7.467214\n",
      "31900   Alice_bob_loss:  0.013629101     Eve_loss: 7.3234043\n",
      "32000   Alice_bob_loss:  0.0056796726     Eve_loss: 7.410398\n",
      "32100   Alice_bob_loss:  0.004211004     Eve_loss: 7.4821057\n",
      "32200   Alice_bob_loss:  0.0052623167     Eve_loss: 7.4304857\n",
      "32300   Alice_bob_loss:  0.004913429     Eve_loss: 7.4425135\n",
      "32400   Alice_bob_loss:  0.005022276     Eve_loss: 7.469593\n",
      "32500   Alice_bob_loss:  0.0047071124     Eve_loss: 7.464927\n",
      "32600   Alice_bob_loss:  0.004236697     Eve_loss: 7.478434\n",
      "32700   Alice_bob_loss:  0.0046494734     Eve_loss: 7.4811053\n",
      "32800   Alice_bob_loss:  0.004394472     Eve_loss: 7.476589\n",
      "32900   Alice_bob_loss:  0.006603053     Eve_loss: 7.480172\n",
      "33000   Alice_bob_loss:  0.004094638     Eve_loss: 7.488204\n",
      "33100   Alice_bob_loss:  0.0042378297     Eve_loss: 7.49935\n",
      "33200   Alice_bob_loss:  0.004696045     Eve_loss: 7.487213\n",
      "33300   Alice_bob_loss:  0.004624448     Eve_loss: 7.4936814\n",
      "33400   Alice_bob_loss:  0.0044410434     Eve_loss: 7.480221\n",
      "33500   Alice_bob_loss:  0.004040181     Eve_loss: 7.504487\n",
      "33600   Alice_bob_loss:  0.0045032594     Eve_loss: 7.4841366\n",
      "33700   Alice_bob_loss:  0.0042802687     Eve_loss: 7.4891076\n",
      "33800   Alice_bob_loss:  0.004392833     Eve_loss: 7.483813\n",
      "33900   Alice_bob_loss:  0.004405575     Eve_loss: 7.478837\n",
      "34000   Alice_bob_loss:  0.0042986493     Eve_loss: 7.484622\n",
      "34100   Alice_bob_loss:  0.004501034     Eve_loss: 7.4772854\n",
      "34200   Alice_bob_loss:  0.0043960623     Eve_loss: 7.4825644\n",
      "34300   Alice_bob_loss:  0.0041861795     Eve_loss: 7.4849005\n",
      "34400   Alice_bob_loss:  0.004721219     Eve_loss: 7.4506025\n",
      "34500   Alice_bob_loss:  0.005283145     Eve_loss: 7.4321194\n",
      "34600   Alice_bob_loss:  0.004494447     Eve_loss: 7.469935\n",
      "34700   Alice_bob_loss:  0.004448723     Eve_loss: 7.46511\n",
      "34800   Alice_bob_loss:  0.0045293374     Eve_loss: 7.4620953\n",
      "34900   Alice_bob_loss:  0.004770428     Eve_loss: 7.465564\n",
      "35000   Alice_bob_loss:  0.0043890206     Eve_loss: 7.4706516\n",
      "35100   Alice_bob_loss:  0.006573985     Eve_loss: 7.478265\n",
      "35200   Alice_bob_loss:  0.004583988     Eve_loss: 7.472032\n",
      "35300   Alice_bob_loss:  0.0045791427     Eve_loss: 7.458924\n",
      "35400   Alice_bob_loss:  0.004434905     Eve_loss: 7.4661846\n",
      "35500   Alice_bob_loss:  0.00457059     Eve_loss: 7.4590206\n",
      "35600   Alice_bob_loss:  0.0045523085     Eve_loss: 7.460623\n",
      "35700   Alice_bob_loss:  0.006590269     Eve_loss: 7.3512535\n",
      "35800   Alice_bob_loss:  0.0046689855     Eve_loss: 7.454343\n",
      "35900   Alice_bob_loss:  0.0039962297     Eve_loss: 7.495058\n",
      "36000   Alice_bob_loss:  0.005517488     Eve_loss: 7.452031\n",
      "36100   Alice_bob_loss:  0.0048461026     Eve_loss: 7.4555182\n",
      "36200   Alice_bob_loss:  0.0051228274     Eve_loss: 7.4443603\n",
      "36300   Alice_bob_loss:  0.0049823658     Eve_loss: 7.4404573\n",
      "36400   Alice_bob_loss:  0.005032819     Eve_loss: 7.432179\n",
      "36500   Alice_bob_loss:  0.0050739124     Eve_loss: 7.429161\n",
      "36600   Alice_bob_loss:  0.0053044455     Eve_loss: 7.4410906\n",
      "36700   Alice_bob_loss:  0.005045251     Eve_loss: 7.4409876\n",
      "36800   Alice_bob_loss:  0.005785947     Eve_loss: 7.429746\n",
      "36900   Alice_bob_loss:  0.005058602     Eve_loss: 7.431127\n",
      "37000   Alice_bob_loss:  0.00530858     Eve_loss: 7.4301233\n",
      "37100   Alice_bob_loss:  0.005274706     Eve_loss: 7.4397926\n",
      "37200   Alice_bob_loss:  0.004598604     Eve_loss: 7.472245\n",
      "37300   Alice_bob_loss:  0.004986065     Eve_loss: 7.4605193\n",
      "37400   Alice_bob_loss:  0.0039618076     Eve_loss: 7.4969354\n",
      "37500   Alice_bob_loss:  0.004543409     Eve_loss: 7.469327\n",
      "37600   Alice_bob_loss:  0.0045967014     Eve_loss: 7.4665885\n",
      "37700   Alice_bob_loss:  0.0055969865     Eve_loss: 7.401735\n",
      "37800   Alice_bob_loss:  0.003775073     Eve_loss: 7.5099206\n",
      "37900   Alice_bob_loss:  0.0038307668     Eve_loss: 7.5049925\n",
      "38000   Alice_bob_loss:  0.0040217303     Eve_loss: 7.493047\n",
      "38100   Alice_bob_loss:  0.0043272832     Eve_loss: 7.4734206\n",
      "38200   Alice_bob_loss:  0.0041033863     Eve_loss: 7.4865108\n",
      "38300   Alice_bob_loss:  0.004539956     Eve_loss: 7.473591\n",
      "38400   Alice_bob_loss:  0.005610808     Eve_loss: 7.4684634\n",
      "38500   Alice_bob_loss:  0.0048432252     Eve_loss: 7.441817\n",
      "38600   Alice_bob_loss:  0.005064414     Eve_loss: 7.4639187\n",
      "38700   Alice_bob_loss:  0.005365883     Eve_loss: 7.4554944\n",
      "38800   Alice_bob_loss:  0.005034746     Eve_loss: 7.4514065\n",
      "38900   Alice_bob_loss:  0.0059997994     Eve_loss: 7.4343452\n",
      "39000   Alice_bob_loss:  0.0056530726     Eve_loss: 7.4411306\n",
      "39100   Alice_bob_loss:  0.0051422366     Eve_loss: 7.438534\n",
      "39200   Alice_bob_loss:  0.0046663536     Eve_loss: 7.45839\n",
      "39300   Alice_bob_loss:  0.005613468     Eve_loss: 7.431139\n",
      "39400   Alice_bob_loss:  0.0052130665     Eve_loss: 7.426612\n",
      "39500   Alice_bob_loss:  0.0053926473     Eve_loss: 7.447828\n",
      "39600   Alice_bob_loss:  0.005458645     Eve_loss: 7.4225283\n",
      "39700   Alice_bob_loss:  0.0075889737     Eve_loss: 7.3025804\n",
      "39800   Alice_bob_loss:  0.0054639387     Eve_loss: 7.4094152\n",
      "39900   Alice_bob_loss:  0.0042784438     Eve_loss: 7.4777813\n",
      "40000   Alice_bob_loss:  0.0048514567     Eve_loss: 7.4435315\n",
      "40100   Alice_bob_loss:  0.0052948627     Eve_loss: 7.452308\n",
      "40200   Alice_bob_loss:  0.0047201714     Eve_loss: 7.4502134\n",
      "40300   Alice_bob_loss:  0.0049305763     Eve_loss: 7.4514823\n",
      "40400   Alice_bob_loss:  0.0045654834     Eve_loss: 7.4587226\n",
      "40500   Alice_bob_loss:  0.0054578115     Eve_loss: 7.4409122\n",
      "40600   Alice_bob_loss:  0.006000784     Eve_loss: 7.4258842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40700   Alice_bob_loss:  0.0047346354     Eve_loss: 7.4541097\n",
      "40800   Alice_bob_loss:  0.0047703036     Eve_loss: 7.4493103\n",
      "40900   Alice_bob_loss:  0.00534089     Eve_loss: 7.4267664\n",
      "41000   Alice_bob_loss:  0.006077546     Eve_loss: 7.4199038\n",
      "41100   Alice_bob_loss:  0.005422768     Eve_loss: 7.410333\n",
      "41200   Alice_bob_loss:  0.005261914     Eve_loss: 7.4351206\n",
      "41300   Alice_bob_loss:  0.009040753     Eve_loss: 7.2384377\n",
      "41400   Alice_bob_loss:  0.0056938296     Eve_loss: 7.3967476\n",
      "41500   Alice_bob_loss:  0.00450538     Eve_loss: 7.4643316\n",
      "41600   Alice_bob_loss:  0.0055804835     Eve_loss: 7.4029284\n",
      "41700   Alice_bob_loss:  0.0056205965     Eve_loss: 7.4179363\n",
      "41800   Alice_bob_loss:  0.005624818     Eve_loss: 7.432817\n",
      "41900   Alice_bob_loss:  0.0055783344     Eve_loss: 7.430791\n",
      "42000   Alice_bob_loss:  0.005507999     Eve_loss: 7.4183393\n",
      "42100   Alice_bob_loss:  0.0053579183     Eve_loss: 7.4137278\n",
      "42200   Alice_bob_loss:  0.00551927     Eve_loss: 7.4222283\n",
      "42300   Alice_bob_loss:  0.0050137076     Eve_loss: 7.44361\n",
      "42400   Alice_bob_loss:  0.007818328     Eve_loss: 7.292774\n",
      "42500   Alice_bob_loss:  0.00481007     Eve_loss: 7.4462075\n",
      "42600   Alice_bob_loss:  0.004623869     Eve_loss: 7.4567175\n",
      "42700   Alice_bob_loss:  0.0046332246     Eve_loss: 7.458037\n",
      "42800   Alice_bob_loss:  0.004812328     Eve_loss: 7.444848\n",
      "42900   Alice_bob_loss:  0.004746384     Eve_loss: 7.4729285\n",
      "43000   Alice_bob_loss:  0.0046029226     Eve_loss: 7.4590616\n",
      "43100   Alice_bob_loss:  0.0047824495     Eve_loss: 7.456959\n",
      "43200   Alice_bob_loss:  0.004682565     Eve_loss: 7.4715633\n",
      "43300   Alice_bob_loss:  0.004197851     Eve_loss: 7.485718\n",
      "43400   Alice_bob_loss:  0.0043579186     Eve_loss: 7.475383\n",
      "43500   Alice_bob_loss:  0.004666013     Eve_loss: 7.474944\n",
      "43600   Alice_bob_loss:  0.004258718     Eve_loss: 7.4826336\n",
      "43700   Alice_bob_loss:  0.004589713     Eve_loss: 7.4795504\n",
      "43800   Alice_bob_loss:  0.0041653686     Eve_loss: 7.486089\n",
      "43900   Alice_bob_loss:  0.0031951834     Eve_loss: 7.5486975\n",
      "44000   Alice_bob_loss:  0.0044374573     Eve_loss: 7.4680357\n",
      "44100   Alice_bob_loss:  0.0037799075     Eve_loss: 7.5105777\n",
      "44200   Alice_bob_loss:  0.0046616895     Eve_loss: 7.4691153\n",
      "44300   Alice_bob_loss:  0.0049783876     Eve_loss: 7.452634\n",
      "44400   Alice_bob_loss:  0.004635047     Eve_loss: 7.4711046\n",
      "44500   Alice_bob_loss:  0.0046235863     Eve_loss: 7.480191\n",
      "44600   Alice_bob_loss:  0.004130806     Eve_loss: 7.50739\n",
      "44700   Alice_bob_loss:  0.004204636     Eve_loss: 7.5132914\n",
      "44800   Alice_bob_loss:  0.0043132813     Eve_loss: 7.4892087\n",
      "44900   Alice_bob_loss:  0.004196882     Eve_loss: 7.5043793\n",
      "45000   Alice_bob_loss:  0.0038105012     Eve_loss: 7.5232997\n",
      "45100   Alice_bob_loss:  0.003677822     Eve_loss: 7.516709\n",
      "45200   Alice_bob_loss:  0.004215152     Eve_loss: 7.5164776\n",
      "45300   Alice_bob_loss:  0.0032502315     Eve_loss: 7.5495877\n",
      "45400   Alice_bob_loss:  0.0033850672     Eve_loss: 7.5354004\n",
      "45500   Alice_bob_loss:  0.002557046     Eve_loss: 7.596383\n",
      "45600   Alice_bob_loss:  0.0022335295     Eve_loss: 7.62265\n",
      "45700   Alice_bob_loss:  0.0024258778     Eve_loss: 7.606385\n",
      "45800   Alice_bob_loss:  0.0020470882     Eve_loss: 7.64094\n",
      "45900   Alice_bob_loss:  0.0031192033     Eve_loss: 7.5559163\n",
      "46000   Alice_bob_loss:  0.0026396164     Eve_loss: 7.596903\n",
      "46100   Alice_bob_loss:  0.0043863375     Eve_loss: 7.5307384\n",
      "46200   Alice_bob_loss:  0.003558849     Eve_loss: 7.5348277\n",
      "46300   Alice_bob_loss:  0.0027908832     Eve_loss: 7.5771914\n",
      "46400   Alice_bob_loss:  0.0030548652     Eve_loss: 7.573004\n",
      "46500   Alice_bob_loss:  0.0030430846     Eve_loss: 7.5582533\n",
      "46600   Alice_bob_loss:  0.004909662     Eve_loss: 7.4394326\n",
      "46700   Alice_bob_loss:  0.0030105386     Eve_loss: 7.5622845\n",
      "46800   Alice_bob_loss:  0.0023337845     Eve_loss: 7.615324\n",
      "46900   Alice_bob_loss:  0.0022295204     Eve_loss: 7.6259327\n",
      "47000   Alice_bob_loss:  0.003309316     Eve_loss: 7.548256\n",
      "47100   Alice_bob_loss:  0.0023433384     Eve_loss: 7.6139364\n",
      "47200   Alice_bob_loss:  0.0031842114     Eve_loss: 7.5848675\n",
      "47300   Alice_bob_loss:  0.0020759357     Eve_loss: 7.6367235\n",
      "47400   Alice_bob_loss:  0.0028533821     Eve_loss: 7.5717063\n",
      "47500   Alice_bob_loss:  0.0032034318     Eve_loss: 7.546882\n",
      "47600   Alice_bob_loss:  0.0032790694     Eve_loss: 7.5560484\n",
      "47700   Alice_bob_loss:  0.003183549     Eve_loss: 7.5496244\n",
      "47800   Alice_bob_loss:  0.0028914064     Eve_loss: 7.579644\n",
      "47900   Alice_bob_loss:  0.0032972286     Eve_loss: 7.5544863\n",
      "48000   Alice_bob_loss:  0.0038096297     Eve_loss: 7.506748\n",
      "48100   Alice_bob_loss:  0.0027796663     Eve_loss: 7.57883\n",
      "48200   Alice_bob_loss:  0.0019260453     Eve_loss: 7.6506386\n",
      "48300   Alice_bob_loss:  0.0036727733     Eve_loss: 7.5154905\n",
      "48400   Alice_bob_loss:  0.0018772008     Eve_loss: 7.654067\n",
      "48500   Alice_bob_loss:  0.0030151566     Eve_loss: 7.5611925\n",
      "48600   Alice_bob_loss:  0.0033775985     Eve_loss: 7.548423\n",
      "48700   Alice_bob_loss:  0.0029722317     Eve_loss: 7.564914\n",
      "48800   Alice_bob_loss:  0.04644363     Eve_loss: 7.5319967\n",
      "48900   Alice_bob_loss:  0.003020578     Eve_loss: 7.560752\n",
      "49000   Alice_bob_loss:  0.0025360335     Eve_loss: 7.5992537\n",
      "49100   Alice_bob_loss:  0.003025166     Eve_loss: 7.56048\n",
      "49200   Alice_bob_loss:  0.003137387     Eve_loss: 7.574234\n",
      "49300   Alice_bob_loss:  0.003066235     Eve_loss: 7.557927\n",
      "49400   Alice_bob_loss:  0.002568368     Eve_loss: 7.594942\n",
      "49500   Alice_bob_loss:  0.0027510645     Eve_loss: 7.5822325\n",
      "49600   Alice_bob_loss:  0.002873434     Eve_loss: 7.5703034\n",
      "49700   Alice_bob_loss:  0.0032386812     Eve_loss: 7.5660863\n",
      "49800   Alice_bob_loss:  0.0031333964     Eve_loss: 7.550837\n",
      "49900   Alice_bob_loss:  0.0031104644     Eve_loss: 7.5540543\n",
      "50000   Alice_bob_loss:  0.003047811     Eve_loss: 7.575583\n",
      "50100   Alice_bob_loss:  0.0035609042     Eve_loss: 7.5230365\n",
      "50200   Alice_bob_loss:  0.0027715322     Eve_loss: 7.5801196\n",
      "50300   Alice_bob_loss:  0.0024431986     Eve_loss: 7.6054945\n",
      "50400   Alice_bob_loss:  0.0031595582     Eve_loss: 7.5508304\n",
      "50500   Alice_bob_loss:  0.004142656     Eve_loss: 7.5755973\n",
      "50600   Alice_bob_loss:  0.0042572017     Eve_loss: 7.501438\n",
      "50700   Alice_bob_loss:  0.0038635782     Eve_loss: 7.504533\n",
      "50800   Alice_bob_loss:  0.0035381126     Eve_loss: 7.5259933\n",
      "50900   Alice_bob_loss:  0.005550234     Eve_loss: 7.4040937\n",
      "51000   Alice_bob_loss:  0.0037286945     Eve_loss: 7.5126266\n",
      "51100   Alice_bob_loss:  0.0036569096     Eve_loss: 7.5163\n",
      "51200   Alice_bob_loss:  0.0038286739     Eve_loss: 7.5045786\n",
      "51300   Alice_bob_loss:  0.0034496044     Eve_loss: 7.5311146\n",
      "51400   Alice_bob_loss:  0.0039311894     Eve_loss: 7.525569\n",
      "51500   Alice_bob_loss:  0.0023326424     Eve_loss: 7.617277\n",
      "51600   Alice_bob_loss:  0.0035754694     Eve_loss: 7.5230956\n",
      "51700   Alice_bob_loss:  0.0034813841     Eve_loss: 7.529791\n",
      "51800   Alice_bob_loss:  0.0036037643     Eve_loss: 7.5246515\n",
      "51900   Alice_bob_loss:  0.0033298717     Eve_loss: 7.5378065\n",
      "52000   Alice_bob_loss:  0.0042755324     Eve_loss: 7.477677\n",
      "52100   Alice_bob_loss:  0.003044524     Eve_loss: 7.5599995\n",
      "52200   Alice_bob_loss:  0.0026399747     Eve_loss: 7.5907135\n",
      "52300   Alice_bob_loss:  0.002593605     Eve_loss: 7.594178\n",
      "52400   Alice_bob_loss:  0.003559904     Eve_loss: 7.523822\n",
      "52500   Alice_bob_loss:  0.0038750977     Eve_loss: 7.516478\n",
      "52600   Alice_bob_loss:  0.002813081     Eve_loss: 7.5779786\n",
      "52700   Alice_bob_loss:  0.0033107523     Eve_loss: 7.540712\n",
      "52800   Alice_bob_loss:  0.004013195     Eve_loss: 7.5207896\n",
      "52900   Alice_bob_loss:  0.003664945     Eve_loss: 7.516946\n",
      "53000   Alice_bob_loss:  0.003999394     Eve_loss: 7.5113854\n",
      "53100   Alice_bob_loss:  0.0035824797     Eve_loss: 7.5313454\n",
      "53200   Alice_bob_loss:  0.0034284585     Eve_loss: 7.5356717\n",
      "53300   Alice_bob_loss:  0.0035110556     Eve_loss: 7.5379725\n",
      "53400   Alice_bob_loss:  0.0033291222     Eve_loss: 7.5460625\n",
      "53500   Alice_bob_loss:  0.003116924     Eve_loss: 7.5565443\n",
      "53600   Alice_bob_loss:  0.0035213938     Eve_loss: 7.5435314\n",
      "53700   Alice_bob_loss:  0.0034193394     Eve_loss: 7.536193\n",
      "53800   Alice_bob_loss:  0.003890713     Eve_loss: 7.5019855\n",
      "53900   Alice_bob_loss:  0.0028753532     Eve_loss: 7.573392\n",
      "54000   Alice_bob_loss:  0.0025516683     Eve_loss: 7.5994344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54100   Alice_bob_loss:  0.0030885485     Eve_loss: 7.5584116\n",
      "54200   Alice_bob_loss:  0.0034145797     Eve_loss: 7.5396357\n",
      "54300   Alice_bob_loss:  0.0035000802     Eve_loss: 7.5637016\n",
      "54400   Alice_bob_loss:  0.003275801     Eve_loss: 7.54433\n",
      "54500   Alice_bob_loss:  0.002039103     Eve_loss: 7.642967\n",
      "54600   Alice_bob_loss:  0.0029337516     Eve_loss: 7.5724354\n",
      "54700   Alice_bob_loss:  0.0030764414     Eve_loss: 7.570863\n",
      "54800   Alice_bob_loss:  0.0028225495     Eve_loss: 7.576127\n",
      "54900   Alice_bob_loss:  0.0028440426     Eve_loss: 7.5723205\n",
      "55000   Alice_bob_loss:  0.002864454     Eve_loss: 7.5934153\n",
      "55100   Alice_bob_loss:  0.0029686005     Eve_loss: 7.586692\n",
      "55200   Alice_bob_loss:  0.00766124     Eve_loss: 7.4715724\n",
      "55300   Alice_bob_loss:  0.0029100555     Eve_loss: 7.5690203\n",
      "55400   Alice_bob_loss:  0.0023430306     Eve_loss: 7.615801\n",
      "55500   Alice_bob_loss:  0.0023349738     Eve_loss: 7.615124\n",
      "55600   Alice_bob_loss:  0.0031586834     Eve_loss: 7.5578446\n",
      "55700   Alice_bob_loss:  0.0030004722     Eve_loss: 7.5635214\n",
      "55800   Alice_bob_loss:  0.0024796221     Eve_loss: 7.6015673\n",
      "55900   Alice_bob_loss:  0.003051581     Eve_loss: 7.5580316\n",
      "56000   Alice_bob_loss:  0.0027114535     Eve_loss: 7.6071267\n",
      "56100   Alice_bob_loss:  0.002987621     Eve_loss: 7.5665317\n",
      "56200   Alice_bob_loss:  0.0033905832     Eve_loss: 7.5772047\n",
      "56300   Alice_bob_loss:  0.0031697478     Eve_loss: 7.5789866\n",
      "56400   Alice_bob_loss:  0.002638363     Eve_loss: 7.5886006\n",
      "56500   Alice_bob_loss:  0.002721721     Eve_loss: 7.6047106\n",
      "56600   Alice_bob_loss:  0.0042990525     Eve_loss: 7.475928\n",
      "56700   Alice_bob_loss:  0.0027654779     Eve_loss: 7.5808525\n",
      "56800   Alice_bob_loss:  0.0023311286     Eve_loss: 7.6160707\n",
      "56900   Alice_bob_loss:  0.0019349826     Eve_loss: 7.650185\n",
      "57000   Alice_bob_loss:  0.0018658702     Eve_loss: 7.6568623\n",
      "57100   Alice_bob_loss:  0.0022732553     Eve_loss: 7.621442\n",
      "57200   Alice_bob_loss:  0.001946007     Eve_loss: 7.6503115\n",
      "57300   Alice_bob_loss:  0.0024407716     Eve_loss: 7.6075354\n",
      "57400   Alice_bob_loss:  0.0027206906     Eve_loss: 7.631514\n",
      "57500   Alice_bob_loss:  0.0024076246     Eve_loss: 7.6101704\n",
      "57600   Alice_bob_loss:  0.0025873014     Eve_loss: 7.603052\n",
      "57700   Alice_bob_loss:  0.0021268437     Eve_loss: 7.6363344\n",
      "57800   Alice_bob_loss:  0.0028490247     Eve_loss: 7.5738325\n",
      "57900   Alice_bob_loss:  0.0017703099     Eve_loss: 7.666273\n",
      "58000   Alice_bob_loss:  0.0015785614     Eve_loss: 7.6862354\n",
      "58100   Alice_bob_loss:  0.0017673471     Eve_loss: 7.666049\n",
      "58200   Alice_bob_loss:  0.003340751     Eve_loss: 7.601058\n",
      "58300   Alice_bob_loss:  0.0017942669     Eve_loss: 7.664359\n",
      "58400   Alice_bob_loss:  0.0018874076     Eve_loss: 7.6564054\n",
      "58500   Alice_bob_loss:  0.0030907448     Eve_loss: 7.5562024\n",
      "58600   Alice_bob_loss:  0.0022685204     Eve_loss: 7.621832\n",
      "58700   Alice_bob_loss:  0.0020903514     Eve_loss: 7.6382103\n",
      "58800   Alice_bob_loss:  0.0017632256     Eve_loss: 7.6681414\n",
      "58900   Alice_bob_loss:  0.0016937345     Eve_loss: 7.676413\n",
      "59000   Alice_bob_loss:  0.0019404975     Eve_loss: 7.652192\n",
      "59100   Alice_bob_loss:  0.0016680581     Eve_loss: 7.678399\n",
      "59200   Alice_bob_loss:  0.002838746     Eve_loss: 7.5755067\n",
      "59300   Alice_bob_loss:  0.0023446402     Eve_loss: 7.612823\n",
      "59400   Alice_bob_loss:  0.0022572868     Eve_loss: 7.6230116\n",
      "59500   Alice_bob_loss:  0.0023937149     Eve_loss: 7.6245966\n",
      "59600   Alice_bob_loss:  0.0026388564     Eve_loss: 7.6098566\n",
      "59700   Alice_bob_loss:  0.0023064124     Eve_loss: 7.616944\n",
      "59800   Alice_bob_loss:  0.002231482     Eve_loss: 7.625181\n",
      "59900   Alice_bob_loss:  0.002388973     Eve_loss: 7.611952\n",
      "60000   Alice_bob_loss:  0.0026832432     Eve_loss: 7.604962\n",
      "60100   Alice_bob_loss:  0.0023692644     Eve_loss: 7.6114564\n",
      "60200   Alice_bob_loss:  0.0038621835     Eve_loss: 7.504319\n",
      "60300   Alice_bob_loss:  0.0025202087     Eve_loss: 7.6030483\n",
      "60400   Alice_bob_loss:  0.002031348     Eve_loss: 7.6428022\n",
      "60500   Alice_bob_loss:  0.0018014349     Eve_loss: 7.6643953\n",
      "60600   Alice_bob_loss:  0.0016759326     Eve_loss: 7.676078\n",
      "60700   Alice_bob_loss:  0.0013867544     Eve_loss: 7.7083826\n",
      "60800   Alice_bob_loss:  0.005856703     Eve_loss: 7.626499\n",
      "60900   Alice_bob_loss:  0.0032725313     Eve_loss: 7.60614\n",
      "61000   Alice_bob_loss:  0.002269334     Eve_loss: 7.621834\n",
      "61100   Alice_bob_loss:  0.0022057958     Eve_loss: 7.625424\n",
      "61200   Alice_bob_loss:  0.002209035     Eve_loss: 7.632489\n",
      "61300   Alice_bob_loss:  0.002940193     Eve_loss: 7.5829854\n",
      "61400   Alice_bob_loss:  0.0021422354     Eve_loss: 7.6336575\n",
      "61500   Alice_bob_loss:  0.0023759117     Eve_loss: 7.634978\n",
      "61600   Alice_bob_loss:  0.0025773223     Eve_loss: 7.598478\n",
      "61700   Alice_bob_loss:  0.0027055673     Eve_loss: 7.5891137\n",
      "61800   Alice_bob_loss:  0.002389291     Eve_loss: 7.6125875\n",
      "61900   Alice_bob_loss:  0.0022103009     Eve_loss: 7.6248994\n",
      "62000   Alice_bob_loss:  0.0043142773     Eve_loss: 7.4748244\n",
      "62100   Alice_bob_loss:  0.0027059158     Eve_loss: 7.5862446\n",
      "62200   Alice_bob_loss:  0.0023676078     Eve_loss: 7.6129036\n",
      "62300   Alice_bob_loss:  0.0020732423     Eve_loss: 7.6393013\n",
      "62400   Alice_bob_loss:  0.0018489986     Eve_loss: 7.659175\n",
      "62500   Alice_bob_loss:  0.0016841536     Eve_loss: 7.675725\n",
      "62600   Alice_bob_loss:  0.0021095588     Eve_loss: 7.65759\n",
      "62700   Alice_bob_loss:  0.0020696481     Eve_loss: 7.638338\n",
      "62800   Alice_bob_loss:  0.0018293278     Eve_loss: 7.662418\n",
      "62900   Alice_bob_loss:  0.0024720265     Eve_loss: 7.607793\n",
      "63000   Alice_bob_loss:  0.0024196324     Eve_loss: 7.6139708\n",
      "63100   Alice_bob_loss:  0.002670235     Eve_loss: 7.591757\n",
      "63200   Alice_bob_loss:  0.0033224276     Eve_loss: 7.6213837\n",
      "63300   Alice_bob_loss:  0.0024322618     Eve_loss: 7.6081305\n",
      "63400   Alice_bob_loss:  0.0023601498     Eve_loss: 7.61298\n",
      "63500   Alice_bob_loss:  0.0026854887     Eve_loss: 7.5843735\n",
      "63600   Alice_bob_loss:  0.0025840634     Eve_loss: 7.594579\n",
      "63700   Alice_bob_loss:  0.0024912253     Eve_loss: 7.611905\n",
      "63800   Alice_bob_loss:  0.0026226812     Eve_loss: 7.620363\n",
      "63900   Alice_bob_loss:  0.0027096146     Eve_loss: 7.6385126\n",
      "64000   Alice_bob_loss:  0.0024794862     Eve_loss: 7.60248\n",
      "64100   Alice_bob_loss:  0.0021515195     Eve_loss: 7.6354227\n",
      "64200   Alice_bob_loss:  0.0034749787     Eve_loss: 7.627482\n",
      "64300   Alice_bob_loss:  0.0024832198     Eve_loss: 7.631544\n",
      "64400   Alice_bob_loss:  0.0018662313     Eve_loss: 7.6565876\n",
      "64500   Alice_bob_loss:  0.002930564     Eve_loss: 7.6357236\n",
      "64600   Alice_bob_loss:  0.0021701783     Eve_loss: 7.649418\n",
      "64700   Alice_bob_loss:  0.0020706675     Eve_loss: 7.679281\n",
      "64800   Alice_bob_loss:  0.002159007     Eve_loss: 7.6842346\n",
      "64900   Alice_bob_loss:  0.00204755     Eve_loss: 7.6664233\n",
      "65000   Alice_bob_loss:  0.0018486418     Eve_loss: 7.6639013\n",
      "65100   Alice_bob_loss:  0.0018240513     Eve_loss: 7.6673317\n",
      "65200   Alice_bob_loss:  0.0015248423     Eve_loss: 7.6907463\n",
      "65300   Alice_bob_loss:  0.0019999174     Eve_loss: 7.6808314\n",
      "65400   Alice_bob_loss:  0.002511423     Eve_loss: 7.6788225\n",
      "65500   Alice_bob_loss:  0.0018510947     Eve_loss: 7.6566567\n",
      "65600   Alice_bob_loss:  0.002111037     Eve_loss: 7.6559086\n",
      "65700   Alice_bob_loss:  0.0020359321     Eve_loss: 7.6481338\n",
      "65800   Alice_bob_loss:  0.0016385722     Eve_loss: 7.674156\n",
      "65900   Alice_bob_loss:  0.0019331807     Eve_loss: 7.6528974\n",
      "66000   Alice_bob_loss:  0.0018391146     Eve_loss: 7.6589804\n",
      "66100   Alice_bob_loss:  0.0022129815     Eve_loss: 7.6444025\n",
      "66200   Alice_bob_loss:  0.0019114392     Eve_loss: 7.6506767\n",
      "66300   Alice_bob_loss:  0.0020808617     Eve_loss: 7.637991\n",
      "66400   Alice_bob_loss:  0.0026044254     Eve_loss: 7.6121073\n",
      "66500   Alice_bob_loss:  0.0020949603     Eve_loss: 7.635249\n",
      "66600   Alice_bob_loss:  0.0024291584     Eve_loss: 7.62431\n",
      "66700   Alice_bob_loss:  0.0025032654     Eve_loss: 7.600646\n",
      "66800   Alice_bob_loss:  0.002308299     Eve_loss: 7.6162224\n",
      "66900   Alice_bob_loss:  0.0026309271     Eve_loss: 7.608784\n",
      "67000   Alice_bob_loss:  0.0027333468     Eve_loss: 7.604962\n",
      "67100   Alice_bob_loss:  0.0025870935     Eve_loss: 7.620989\n",
      "67200   Alice_bob_loss:  0.0020615107     Eve_loss: 7.636958\n",
      "67300   Alice_bob_loss:  0.0021589368     Eve_loss: 7.629637\n",
      "67400   Alice_bob_loss:  0.0023461897     Eve_loss: 7.614526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67500   Alice_bob_loss:  0.00270014     Eve_loss: 7.587865\n",
      "67600   Alice_bob_loss:  0.0022335264     Eve_loss: 7.6239843\n",
      "67700   Alice_bob_loss:  0.002738588     Eve_loss: 7.585483\n",
      "67800   Alice_bob_loss:  0.0037129065     Eve_loss: 7.5572605\n",
      "67900   Alice_bob_loss:  0.002909869     Eve_loss: 7.5785027\n",
      "68000   Alice_bob_loss:  0.0029210781     Eve_loss: 7.5713663\n",
      "68100   Alice_bob_loss:  0.0029025439     Eve_loss: 7.5759983\n",
      "68200   Alice_bob_loss:  0.0025254278     Eve_loss: 7.599039\n",
      "68300   Alice_bob_loss:  0.0032051036     Eve_loss: 7.5692296\n",
      "68400   Alice_bob_loss:  0.002536593     Eve_loss: 7.5988607\n",
      "68500   Alice_bob_loss:  0.0027747594     Eve_loss: 7.58249\n",
      "68600   Alice_bob_loss:  0.0026535613     Eve_loss: 7.5888176\n",
      "68700   Alice_bob_loss:  0.0027884082     Eve_loss: 7.5792036\n",
      "68800   Alice_bob_loss:  0.0031039657     Eve_loss: 7.561712\n",
      "68900   Alice_bob_loss:  0.002912688     Eve_loss: 7.57146\n",
      "69000   Alice_bob_loss:  0.003034979     Eve_loss: 7.559337\n",
      "69100   Alice_bob_loss:  0.0029734634     Eve_loss: 7.582279\n",
      "69200   Alice_bob_loss:  0.0025689004     Eve_loss: 7.5924244\n",
      "69300   Alice_bob_loss:  0.0032513237     Eve_loss: 7.5474286\n",
      "69400   Alice_bob_loss:  0.00312958     Eve_loss: 7.5524273\n",
      "69500   Alice_bob_loss:  0.0032214907     Eve_loss: 7.5677376\n",
      "69600   Alice_bob_loss:  0.003803778     Eve_loss: 7.5468574\n",
      "69700   Alice_bob_loss:  0.0035348323     Eve_loss: 7.542407\n",
      "69800   Alice_bob_loss:  0.0030937842     Eve_loss: 7.556343\n",
      "69900   Alice_bob_loss:  0.0035290874     Eve_loss: 7.5636277\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "import numpy as np\n",
    "\n",
    "print('x')\n",
    "\n",
    "# Input configuration.\n",
    "TEXT_SIZE = 16\n",
    "KEY_SIZE  = 16\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate   = 0.0008\n",
    "batch_size      = 4096\n",
    "sample_size     = 4096*5\n",
    "epochs          = 850000\n",
    "steps_per_epoch = int(sample_size/batch_size)\n",
    "\n",
    "ITERS_PER_ACTOR = 1\n",
    "EVE_MULTIPLIER = 2  # Train Eve 2x for every step of Alice/Bob\n",
    "\n",
    "# Function to return a list of tensor's to be used in training based on the scope of model\n",
    "def get_collection(collection):\n",
    "  return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=collection) \n",
    "\n",
    "# Create two placeholders to hold message and key\n",
    "input_message = tf.placeholder(tf.float32, shape=(batch_size, TEXT_SIZE), name='input_message')\n",
    "input_key     = tf.placeholder(tf.float32, shape=(batch_size, KEY_SIZE), name='input_key')\n",
    "\n",
    "\n",
    "# Function to create individual models for Alice, Bob and Eve.\n",
    "def model(collection, message, key=None):\n",
    "  \n",
    "  if key is not None:\n",
    "    # if there is a key then it's either Alice or Bob model trying to encrypt and decrypt resp\n",
    "    # message and key is concatenated into single tensor and fed as an input\n",
    "    combined_input = tf.concat(axis=1, values=[message, key])\n",
    "  else:\n",
    "    # if no key is present then it's Eve model trying to eavesdrop hence pass the message as input tensor \n",
    "    combined_input = message\n",
    "  \n",
    "  # collection arg is to denote the scope of model which is used to aggregate the \n",
    "  # tensor to make sure all tensor which needs to be trained are inside one scope\n",
    "  with tf.variable_scope(collection):\n",
    "    \n",
    "    \n",
    "    ## Fully connected layer of 16+16 = 32 neurons\n",
    "    fc = tf.layers.dense(combined_input, TEXT_SIZE + KEY_SIZE, activation=tf.nn.relu)\n",
    "    # expand and create channel to be valid for convolution\n",
    "    # i.e convert FC layer a vector of 32 to matrix of (32,1) \n",
    "    fc = tf.expand_dims(fc, 2)\n",
    "    \n",
    "    \n",
    "    ## Convolution Layers - Sigmoid activation function\n",
    "    \n",
    "    # input: (32,1) -> output:(32,2) because filter is 2 which creates 2 channels\n",
    "    conv1 = tf.layers.conv1d( fc,    filters=2, kernel_size=4, strides= 1, padding='SAME',  activation=tf.nn.sigmoid)\n",
    "    \n",
    "    # input: (32,2) -> output:(16,4) because stride is 2 hence result is halved ( i.e 32/2 )\n",
    "    # filter is 4 which creates 4 channels\n",
    "    conv2 = tf.layers.conv1d( conv1, filters=4, kernel_size=2, strides= 2, padding='VALID', activation=tf.nn.sigmoid)\n",
    "    \n",
    "    # input: (16,4) -> output:(16,4) because filter is 4 which creates 4 channels\n",
    "    conv3 = tf.layers.conv1d( conv2, filters=4, kernel_size=1, strides= 1, padding='SAME',  activation=tf.nn.sigmoid)\n",
    "    \n",
    "    \n",
    "    ## Convolution Layers - Tanh activation function\n",
    "    \n",
    "    # input: (16,4) -> output:(16,1) because filter is 1 which creates 1 channel\n",
    "    conv4 = tf.layers.conv1d( conv3, filters=1, kernel_size=1, strides=1, padding='SAME', activation=tf.nn.tanh)\n",
    "    \n",
    "    # Opposite of expand_dims function, here (16,1) tensor is converted to tensor of (16)\n",
    "    conv4 = tf.squeeze(conv4, 2)\n",
    "    \n",
    "    \n",
    "    return conv4\n",
    "\n",
    "def symm_crypto_create(input_message, input_key):\n",
    "  \n",
    "  # Alice takes in message and shared secret key to encrypt and create a ciphertext\n",
    "  Alice_out_ciphertext = model( 'Alice', input_message, input_key)\n",
    "\n",
    "  # Bob takes in ciphertext and shared secret key to decrypt and recreate the original message\n",
    "  Bob_out_message      = model( 'Bob',   Alice_out_ciphertext, input_key)\n",
    "\n",
    "  # Eve only takes in ciphertext and tries to decrypt it without using key\n",
    "  Eve_out_message      = model( 'Eve',   Alice_out_ciphertext)\n",
    "  \n",
    "  return Bob_out_message, Eve_out_message\n",
    "\n",
    "def random_bools(size, n):\n",
    "  \n",
    "  # create a batch size of 'size' with 'n' number of bits per sample\n",
    "  temp =  np.random.random_integers(0, high=1, size=[size, n])\n",
    "  \n",
    "  # Convert 0 -> -1 and 1 -> 1 \n",
    "  temp = temp*2 - 1\n",
    "  \n",
    "  return temp.astype(np.float32)\n",
    "  \n",
    "def get_dataset(sample_size, TEXT_SIZE, KEY_SIZE):\n",
    "\n",
    "  m = random_bools(sample_size, TEXT_SIZE)\n",
    "  k = random_bools(sample_size, KEY_SIZE)\n",
    "  \n",
    "  return m, k\n",
    "\n",
    "def eve_loss(input_message, eve_out_message, batch_size):\n",
    "\n",
    "  # Mapping -1 to 0 and 1 to 1\n",
    "  eve_diff = (eve_out_message + 1.0)/2.0 - (input_message + 1.0)/2.0\n",
    "  \n",
    "  # Eve's average L1 distance Loss of the given batch\n",
    "  loss = (1/batch_size)*tf.reduce_sum(tf.abs(eve_diff))\n",
    "  \n",
    "  return loss\n",
    "\n",
    "def alice_bob_loss(input_message, bob_out_message, Eve_loss, batch_size):\n",
    "\n",
    "  ## Alice-Bob Loss part-1\n",
    "  \n",
    "  # Mapping -1 to 0 and 1 to 1\n",
    "  ab_diff = (bob_out_message + 1.0)/2.0 - (input_message + 1.0)/2.0\n",
    "  \n",
    "  # Alice and Bob's average L1 distance Loss of the given batch\n",
    "  bob_reconstruction_loss = (1/batch_size)*tf.reduce_sum(tf.abs(ab_diff))\n",
    "\n",
    "  ## Alice-Bob Loss part-2\n",
    "  # To make sure Eve at least has 50% of bits wrong so that output simulates random probability of binary output\n",
    "  # ((N/2 - EveLoss)^2)/((N/2)^2)\n",
    "  eve_evedropping_loss = tf.reduce_sum( tf.square(float(TEXT_SIZE) / 2.0 - Eve_loss) / (TEXT_SIZE / 2)**2)\n",
    "\n",
    "  # bobs final reconstruction loss\n",
    "  loss = bob_reconstruction_loss + eve_evedropping_loss\n",
    "  \n",
    "  return loss\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Create symmetric cryptosystem in form of adversarial networks\n",
    "Bob_out, Eve_out = symm_crypto_create(input_message, input_key)\n",
    "\n",
    "# Loss\n",
    "eve_loss       = eve_loss(input_message, Eve_out, batch_size)\n",
    "alice_bob_loss = alice_bob_loss(input_message, Bob_out, eve_loss, batch_size)\n",
    "\n",
    "# Collect each model's tensors\n",
    "alice_vars = get_collection('Alice')\n",
    "bob_vars   = get_collection('Bob')\n",
    "eve_vars   = get_collection('Eve')\n",
    "\n",
    "# optimizers\n",
    "Eve_opt  = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, epsilon=1e-08).minimize(eve_loss, var_list=[eve_vars])\n",
    "bob_opt  = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, epsilon=1e-08).minimize(alice_bob_loss, var_list=[alice_vars + bob_vars]) \n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# DATASET \n",
    "messages, keys = get_dataset(sample_size, TEXT_SIZE, KEY_SIZE)\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  for j in range(steps_per_epoch):\n",
    "    \n",
    "    # select the batch from the samples\n",
    "    batch_messages = messages[j*batch_size: (j+1)*batch_size]\n",
    "    batch_keys     = keys[j*batch_size: (j+1)*batch_size]\n",
    "\n",
    "    # Train Alice and Bob's models\n",
    "    for _ in range(ITERS_PER_ACTOR):\n",
    "      temp = sess.run([bob_opt, alice_bob_loss],feed_dict={input_message:batch_messages , input_key:batch_keys })\n",
    "      Alice_bob_loss = temp[1]\n",
    "\n",
    "    # Train Eve's model\n",
    "    for _ in range(ITERS_PER_ACTOR*EVE_MULTIPLIER):\n",
    "      temp = sess.run([Eve_opt, eve_loss], feed_dict={input_message:batch_messages , input_key:batch_keys })\n",
    "      Eve_loss = temp[1]\n",
    "\n",
    "  # output Alice-Bob loss and Eve's loss after every 100 iterations  \n",
    "  if i%100 == 0:\n",
    "    print(i,'  Alice_bob_loss: ', Alice_bob_loss,'    Eve_loss:', Eve_loss)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
